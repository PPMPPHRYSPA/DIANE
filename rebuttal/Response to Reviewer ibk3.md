We sincerely appreciate your thorough evaluation and valuable feedback on our manuscript. We are grateful for the time and effort you have invested in providing constructive comments. Here are several items we believe to be worth mentioning in our response:

- **Comments to Scalability and Reproducibility**
  - We recognize your concern about the scalability of DIANE given that the initial selection of $2,000$ patients for our data analysis is relatively small. To respond to your concern, we have substantially extended the dataset to include $17,421$ patients, involving both Alzheimer’s disease (AD) and multiple sclerosis (MS) cohorts within the UPMC system. We have posted the knowledge network corresponding to this new dataset in Figure 1 of the attachment.
  - In our most recent experiment based on the larger-scale UPMC dataset, DIANE shows its effectiveness by outperforming BERT [1] and its variants [2,3,4] in two significant tasks: detecting known-relationship pairs and risk prediction. The detailed results are presented in Table 1 and Table 2 of the attachment.
  - We agree with your comment that it is advantageous to further validate DIANE using open-source EHR databases. We are actively working on this, and envision that additional results from these experiments will be included in the updated version of our work.
- **Comments to Explanability**
  - Many supervised or semi-supervised patient phenotyping algorithms rely on gold-standard labels that involve labor-intensive manual annotation on sparsely labeled EHR datasets [5,6]. In comparison, DIANE is an unsupervised method and does not rely on patient-level labels. We can also estimate the patient embedding via the proposed model for the explainability of downstream tasks like patient profiling and risk prediction.
  - Several existing unsupervised zero-shot methods operate like black boxes, lacking solid theoretical grounding to support their performance [7,8]. In contrast, the steps of DIANE are transparent, explainable, and further supported by a robust theoretical performance guarantee. Such a performance guarantee enhances the credibility of DIANE by providing researchers with greater confidence in the validity and correctness of the outcomes.
- **Comments to Limitations and Potential Negative Social Impact**
  - We have pointed out several potential limitations for DIANE in Section 7 of our original manuscript. Recognizing the importance of a thorough and comprehensive understanding of DIANE's limitations, we will include an additional dedicated section to discuss limitations in the future version of our work.
  - One potential negative social impact of our work is that DIANE-based knowledge graph, as presented in Figure 1 of the attachment, might be outdated as we use the dataset before 2019, leading to inaccurate or misleading determinations for future clinicians. For example, COVID-19-related information may be absent on a knowledge graph generated by EHR data collected before late 2019. Consequently, any relationship drawn between COVID-related diseases and drugs based on such a graph could be incorrect. To mitigate this issue, researchers need to continuously update the knowledge graph with current EHR data, ensuring that clinicians are supported with the most up-to-date and accurate information.

We believe the changes we made have substantially improved the clarity, rigor, and significance of our study. We hope our revisions address your concerns.

### References

[1] Jacob Devlin, Ming-Wei Chang, Kenton Lee, and Kristina Toutanova. BERT: pre-training of deep
bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North
American Chapter of the Association for Computational Linguistics: Human Language Technologies,
NAACL-HLT, pages 4171–4186, 2019.

[2] Yu Gu, Robert Tinn, Hao Cheng, Michael Lucas, Naoto Usuyama, Xiaodong Liu, Tristan Naumann,
Jianfeng Gao, and Hoifung Poon. Domain-specific language model pretraining for biomedical natural
language processing. *ACM Transactions on Computing for Healthcare*, 3:1–23, 2021.

[3] Jinhyuk Lee, Wonjin Yoon, Sungdong Kim, Donghyeon Kim, Sunkyu Kim, Chan Ho So, and Jaewoo
Kang. BioBERT: a pre-trained biomedical language representation model for biomedical text mining.
*Bioinformatics*, 36(4):1234–1240, 2020.

[4] Fangyu Liu, Ehsan Shareghi, Zaiqiao Meng, Marco Basaldella, and Nigel Collier. Self-alignment
pretraining for biomedical entity representations. In *Proceedings of the 2021 Conference of the North
American Chapter of the Association for Computational Linguistics: Human Language Technologies*,
pages 4228–4238, 2021.

[5] B. K. Beaulieu-Jones and C. S. Greene. Semi-supervised learning of the electronic health record for
phenotype stratification. *Journal of Biomedical Informatics*, 64:168–178, 2016.

[6] R. L. Figueloa, Q. Zeng-Treitler, S. Kandula, and et al. Predicting sample size required for classification
performance. *Medical Informatics and Decision Making*, 12:8, 2012.

[7] Z. Han, Z. Fu, S. Chen, and J. Yang. Contrastive embedding for generalized zero-shot learning. *CVPR*,
pages 2371–2381, 2021.

[8] I. E. Nogues, J. Wen, Y. Lin, M. Liu, S. K. Tedeschi, A. Geva, T. Cai, and C. Hong. Weakly semi-
supervised phenotyping using electronic health records. *Journal of Biomedical Informatics*, 134:104175,
2022.
